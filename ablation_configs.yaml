# ============================================================================
# PINN-Coupled-PDE-Solver: Ablation Study Configuration
# ============================================================================
# This file defines all experiments for the ICML paper.
# Run with: python run_all_experiments.py --config ablation_configs.yaml
# ============================================================================

meta:
  project: "PINN-Coupled-PDE-Solver"
  target: "ICML 2025"
  primary_metric: "r2_mean"
  seeds: [42, 123, 456]
  output_base: "outputs/icml_experiments"

# ============================================================================
# TIER 0: Main Paper Experiments (Must-Have)
# ============================================================================
# 7 configurations × 3 seeds = 21 runs
# Expected runtime: ~24 GPU-hours

tier0:
  - id: "T0-1-main"
    name: "Main Model (Full Pipeline)"
    description: "Full split-spline model with all components enabled"
    config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: true
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      ctrl_points: 8
      continuity_weight: 0.1
      oracle_voc: false
      no_hpo: true
    expected:
      r2_mean: ">0.99"
      ff_mape: "<2%"
      violations_per_1000: "<1"

  - id: "T0-2-no-split"
    name: "No Split (Single Spline)"
    description: "Ablation: Single spline over [0, Voc] without MPP split"
    config:
      train_curves: true
      use_split: false
      use_anchors: true
      use_projection: true
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      ctrl_points: 12  # More points since no split
      continuity_weight: 0.0  # No continuity needed
      no_hpo: true
    expected:
      r2_mean: "~0.97"
      ff_mape: "~5%"

  - id: "T0-3-no-anchors"
    name: "No Anchors (Direct 45-out)"
    description: "Ablation: Direct 45-point output without anchor prediction"
    config:
      train_curves: true
      direct_curve: true  # DirectCurveNet instead of split-spline
      use_anchors: false
      use_projection: false
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      no_hpo: true
    expected:
      r2_mean: "~0.95"
      ff_mape: "~8%"

  - id: "T0-4-no-projection"
    name: "No Physics Projection"
    description: "Ablation: Disable hard constraint projection (soft only)"
    config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: false  # Key difference
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      ctrl_points: 8
      no_hpo: true
    expected:
      r2_mean: "~0.98"
      violations_per_1000: ">10"

  - id: "T0-5-no-physics-features"
    name: "Raw 31 Parameters Only"
    description: "Ablation: Use only raw 31 COMSOL parameters, no engineered features"
    config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: true
      use_physics_features: false  # Key difference
      drop_weak_features: false
      drop_multicollinear: false
      ctrl_points: 8
      no_hpo: true
    expected:
      r2_mean: "~0.96"

  - id: "T0-6-cvae-baseline"
    name: "CVAE Baseline"
    description: "Conditional VAE generative baseline"
    config:
      train_cvae: true
      train_curves: false
      cvae_latent_dim: 16
      cvae_beta: 0.001
      use_physics_features: true
      no_hpo: true
    expected:
      r2_mean: "~0.95"
      ff_mape: "~8%"

  - id: "T0-7-mlp-baseline"
    name: "Direct MLP Baseline"
    description: "Simple feedforward MLP: 31 → 256 → 128 → 45"
    config:
      train_curves: true
      direct_mlp: true
      hidden_dims: [256, 128]
      use_physics_features: false
      no_hpo: true
    expected:
      r2_mean: "~0.90"
      ff_mape: "~15%"

# ============================================================================
# TIER 1: Hyperparameter Sweeps (Appendix)
# ============================================================================
# 45 runs total across 3 sweeps × 3 seeds

tier1:
  control_points_sweep:
    name: "Control Points Sweep"
    description: "Effect of K control points per region on curve accuracy"
    base_config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: true
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      continuity_weight: 0.1
      no_hpo: true
    sweep_param: "ctrl_points"
    values: [2, 4, 6, 8, 10, 12]
    expected_trend: "Diminishing returns after K=6"

  continuity_sweep:
    name: "Continuity Weight Sweep"
    description: "Effect of C1 continuity loss weight on smoothness vs accuracy"
    base_config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: true
      use_physics_features: true
      drop_weak_features: true
      drop_multicollinear: true
      ctrl_points: 8
      no_hpo: true
    sweep_param: "continuity_weight"
    values: [0.0, 0.01, 0.05, 0.1, 0.5, 1.0]
    expected_trend: "Best around 0.05-0.1"

  feature_count_sweep:
    name: "Physics Feature Count Sweep"
    description: "Effect of number of selected physics features"
    base_config:
      train_curves: true
      use_split: true
      use_anchors: true
      use_projection: true
      drop_weak_features: false  # Control manually
      drop_multicollinear: false
      ctrl_points: 8
      no_hpo: true
    sweep_param: "n_physics_features"
    values: [0, 4, 8, 16, 32, 71]
    expected_trend: "Saturation after ~16 features"

# ============================================================================
# TIER 2: Physics & Sensitivity Analysis (High Impact for Paper)
# ============================================================================

tier2:
  jacobian_analysis:
    name: "Jacobian Sensitivity Analysis"
    description: "Analyze input-output Jacobian for physics interpretation"
    config:
      compute_jacobian: true
      jacobian_samples: 1000
      save_jacobian_stats: true
    outputs:
      - "jacobian_mean.npy"
      - "jacobian_std.npy"
      - "jacobian_heatmap.pdf"
      - "feature_sensitivity_ranking.csv"

  parameter_sensitivity:
    name: "31 Input Parameter Sensitivity"
    description: "One-at-a-time sensitivity analysis for each input parameter"
    config:
      sensitivity_analysis: true
      perturbation_range: [-0.2, 0.2]  # ±20% of normalized range
      n_perturbation_steps: 21
    outputs:
      - "parameter_sensitivity.csv"
      - "sensitivity_spider_plot.pdf"
      - "sensitivity_tornado.pdf"

  physics_validation:
    name: "Physics Constraint Validation"
    description: "Verify learned relationships match drift-diffusion physics"
    config:
      physics_validation: true
      validate_monotonicity: true
      validate_boundaries: true
      validate_fill_factor: true
    checks:
      - "J decreases with V (monotonicity)"
      - "J(0) = Jsc, J(Voc) = 0 (boundary)"
      - "Vmpp < Voc, Jmpp < Jsc (ordering)"
      - "FF = Pmpp / (Jsc × Voc) consistency"

# ============================================================================
# TCN TIER 0: Main Paper Experiments (Primary Pipeline)
# ============================================================================
# 10 configurations × 3 seeds = 30 runs
# Runs via: sbatch slurm_tcn_master_pipeline.sh
# Key finding: Dilated TCN without attention is best.

tcn_tier0:
  - id: "T0-1-DilatedTCN"
    name: "Dilated TCN, No Attention (MAIN MODEL)"
    description: "Best performing configuration: causal dilated convolutions, no self-attention"
    flags: "--architecture tcn --no-attention --use-dilated"

  - id: "T0-2-Conv"
    name: "Standard Conv, No Attention"
    description: "Non-causal 1D convolution with symmetric padding"
    flags: "--architecture conv --no-attention"

  - id: "T0-3-Pointwise"
    name: "Pointwise (1x1), No Attention"
    description: "Position-independent baseline (no temporal mixing)"
    flags: "--architecture pointwise --no-attention"

  - id: "T0-4-DilatedTCN-Attn"
    name: "Dilated TCN WITH Attention"
    description: "Tests whether attention adds value on short sequences"
    flags: "--architecture tcn --use-attention --use-dilated"

  - id: "T0-5-Conv-Attn"
    name: "Conv WITH Attention"
    description: "Non-causal conv with self-attention"
    flags: "--architecture conv --use-attention"

  - id: "T0-6-TCN-NoDilation"
    name: "TCN Without Dilation"
    description: "Isolates the contribution of dilated convolutions"
    flags: "--architecture tcn --no-attention --no-dilated"

  - id: "T0-7-NoScalars"
    name: "No Scalars (Params Only)"
    description: "No Voc/Vmpp external scalar inputs — tests conditioning value"
    note: "No --scalar-files flags passed"

  - id: "T0-8-100kOnly"
    name: "100k Only (No Extra Data)"
    description: "Tests data scaling (no 300k extra dataset)"
    note: "No --params-extra / --iv-extra flags passed"

  - id: "T0-9-200epochs"
    name: "200 Epochs"
    description: "Longer training to test convergence"
    flags: "--architecture tcn --no-attention --use-dilated --max-epochs 200"

  - id: "T0-10-BS512"
    name: "Batch Size 512"
    description: "Larger batch size effect"
    flags: "--architecture tcn --no-attention --use-dilated --batch-size 512"

# TCN Tier 1: Extended Sweeps
tcn_tier1:
  batch_size_sweep:
    name: "Batch Size Sweep"
    values: [64, 256, 512, 1024]
    runs_per_value: 3  # seeds

  epoch_sweep:
    name: "Epoch Sweep"
    values: [50, 150, 200]
    runs_per_value: 3

# ============================================================================
# ADDITIONAL HIGH-IMPACT EXPERIMENTS
# ============================================================================

additional_experiments:
  - id: "A1-oracle-voc"
    name: "Oracle Voc Upper Bound"
    description: "Use true Voc for curve truncation to show upper bound"
    config:
      train_curves: true
      oracle_voc: true
      ctrl_points: 8
      no_hpo: true
    purpose: "Establish ceiling performance"

  - id: "A2-data-scaling"
    name: "Data Scaling Study"
    description: "100k vs 300k vs 400k training samples"
    variants:
      - samples: 100000
      - samples: 300000
      - samples: 400000  # Combined
    purpose: "Show data efficiency"

# ============================================================================
# FIGURE SPECIFICATIONS
# ============================================================================

figures:
  main_paper:
    - id: "fig1_architecture_comparison"
      type: "bar"
      file: "fig_architecture_comparison.pdf"
      experiments: ["T0-1-DilatedTCN", "T0-2-Conv", "T0-3-Pointwise", "T0-4-DilatedTCN-Attn", "T0-5-Conv-Attn", "T0-6-TCN-NoDilation"]
      metric: "r2_median"
      description: "Architecture comparison: R² (mean ± std) across variants"

    - id: "fig2_error_distribution"
      type: "violin"
      file: "fig_error_distribution.pdf"
      experiments: ["T0-1-DilatedTCN", "T0-2-Conv", "T0-3-Pointwise"]
      metric: "mae_median"
      description: "Error distribution (MAE) across main architectures"

    - id: "fig3_ablation_heatmap"
      type: "heatmap"
      file: "fig_ablation_heatmap.pdf"
      experiments: ["T0-1 through T0-10"]
      metrics: ["r2_median", "mae_median", "voc_error", "isc_error"]
      description: "Full ablation heatmap (normalized per column)"

    - id: "fig4_attention_impact"
      type: "paired_bar"
      file: "fig_attention_impact.pdf"
      experiments: ["T0-1 vs T0-4", "T0-2 vs T0-5"]
      description: "Paired comparison: with/without attention"

    - id: "fig5_jv_overlays"
      type: "grid_3x3"
      data: "T0-1-DilatedTCN predictions"
      description: "True vs predicted I-V curves (best/median/worst)"

  appendix:
    - id: "fig_a1_batch_size_sweep"
      type: "line"
      file: "fig_batch_size_sweep.pdf"
      sweep: "batch_size_sweep"
      description: "R² vs batch size"

    - id: "fig_a2_epoch_sweep"
      type: "line"
      file: "fig_epoch_sweep.pdf"
      sweep: "epoch_sweep"
      description: "R² vs training epochs"

    - id: "fig_a3_data_scaling"
      type: "bar"
      file: "fig_data_scaling.pdf"
      description: "100k vs 100k+300k performance comparison"

    - id: "fig_a4_runtime"
      type: "bar"
      file: "fig_runtime_comparison.pdf"
      description: "Training time across architectures"

    - id: "fig_a5_jacobian_heatmap"
      type: "heatmap"
      description: "Mean |∂output/∂input| across features and voltage positions"

    - id: "fig_a6_sensitivity_tornado"
      type: "tornado"
      description: "Top-20 most sensitive parameters"

    - id: "fig_a7_feature_importance"
      type: "bar"
      description: "Feature importance ranking from Jacobian analysis"

# ============================================================================
# TABLE SPECIFICATIONS
# ============================================================================

tables:
  main_paper:
    - id: "table1_main_results"
      file: "table_main_results.tex"
      experiments: ["T0-1-DilatedTCN", "T0-2-Conv", "T0-3-Pointwise", "T0-4-DilatedTCN-Attn"]
      columns: ["R² median ± std", "MAE median", "Voc error", "Isc error"]
      format: "mean ± std over 3 seeds"

    - id: "table2_ablations"
      file: "table_ablations.tex"
      experiments: ["T0-1 through T0-10"]
      columns: ["R² median", "MAE median", "Voc error", "Isc error"]
      format: "mean over 3 seeds"

  appendix:
    - id: "table_a1_full_metrics"
      experiments: "all"
      columns: "all metrics"
      format: "comprehensive"

    - id: "table_a2_hyperparameters"
      content: "TCN architecture hyperparameters for all variants"

# ============================================================================
# RUNTIME ESTIMATES
# ============================================================================

runtime:
  split_spline_tier0:
    runs: 21
    gpu_hours: 24
    wall_time: "~6 hours with 4 GPUs"

  tcn_tier0:
    runs: 30
    gpu_hours: 7
    wall_time: "~7 hours with 1 GPU"

  tcn_tier1:
    runs: 21
    gpu_hours: 5
    wall_time: "~5 hours with 1 GPU"

  total_tcn:
    runs: 51
    gpu_hours: 12
    wall_time: "~12 hours with 1 GPU"

# ============================================================================
# QUALITY CHECKS (Assertions)
# ============================================================================

quality_checks:
  pre_run:
    - "Feature selection uses only train indices"
    - "No data leakage in preprocessing"
    - "Voltage grid matches config.V_GRID"

  post_run:
    - "All 81 runs completed successfully"
    - "Main model R² > 0.99"
    - "No NaN/inf in any metrics"
    - "Monotonicity violations = 0 for main model"
    - "Feature selection stable (>80% overlap across seeds)"

  assertions:
    main_model_r2_threshold: 0.99
    max_violations_per_1000: 1.0
    min_ff_accuracy: 0.98  # FF prediction within 2%
